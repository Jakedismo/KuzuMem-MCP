# Database Configuration
DB_FILENAME="memory-bank.kuzu"

# Server Configuration
PORT=3000
HTTP_STREAM_PORT=3001
HOST=localhost
MCP_STDIO_SERVER=True

# =============================================================================
# Core Memory Optimization Agent - AI Provider Configuration
# =============================================================================

# OpenAI Configuration (for o3, o1-mini models with HIGH reasoning)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic Configuration (for Claude models with extended thinking)
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Optional: Custom API endpoints (uncomment if using proxies or custom endpoints)
# OPENAI_BASE_URL=https://api.openai.com/v1
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# Optional: Default Core Memory Optimization settings
# CORE_MEMORY_DEFAULT_PROVIDER=openai
# CORE_MEMORY_DEFAULT_MODEL=o1-mini
# CORE_MEMORY_DEFAULT_STRATEGY=conservative

# =============================================================================
# Supported Models & Reasoning Configuration
# =============================================================================
#
# OpenAI Models (HIGH Reasoning):
# - o3: Most capable with HIGH reasoning (production)
# - o1-mini: Cost-effective with HIGH reasoning (development)
#
# Anthropic Models (Extended Thinking):
# - claude-3-5-sonnet-20241022: Most capable (production)
# - claude-3-5-haiku-20241022: Fast & cost-effective (development)
#
# Automatic Configuration:
# - OpenAI: reasoning='high', maxReasoningTokens=32768
# - Anthropic: thinking={enabled: true, maxTokens: 2048}
#
# =============================================================================